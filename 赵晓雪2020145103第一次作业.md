 

 

## ***\*8.3分布式计算框架Mapreduce\****

Mapreduce是一个高性能的分布式计算框架，适合处理各种类型的数据，包括结构化、半结构化和非结构化数据，数据量在太字节和拍字节级别，传统方法通常已经无法处理这个量级的数据。

### ***\*MapReduce框架结构\****

MapReduce将分析任务分为大量的并行map任务和reduce汇总任务两类。

#### ***\*MapReduce简单模型\****

对于某些任务来说，可能并不一定需要reduce过程，如只需要对文本的每一行数据做简单的格式转换即可，那么只需要由mapper处理后就可以了。所以MapReduce也有简单的编程模型，该模型只有mapper类，由mapper产生的数据直接写入HDFS.

#### ***\*MapReduce复杂模型\****

对于大部分的任务来说都是需要reduce过程，并且由于任务繁重会启动多个Reducer来进行汇总。如果只用一个Reducer计算所有Mapper的结果，会导致单个Reducer负载过于繁重，大大增加任务的运行周期。

### ***\*MapReduce数据流\****

#### ***\*分片、格式化数据源（InoutFormat）\****

InputFormat主要有两个任务,一个是对源文件进行分片，并确定Mapper的数量，另一个是对一个分片进行格式化，处理成<key,value>形式的数据流，并传给Mapper。

#### ***\*Map过程\****

mapper接收<key, value>形式的数据，并处理成<key,value>形式的数据，具体的处理过程可由用户定义。

（1） Combiner过程

每一个map()都可能会产生大量的本地输出,Combiner的作用就是对map()端的输出先做一次合并，以减少在Map和Reduce节点之间的数据传输量，提高网络I/O性能是Mapreduce一种优化手段之一。

#### ***\*Shuffle过程\****

Shuffle过程是指从Mapper产生的直接输出结果，经过一系列的处理，成为最终的Reducer直接输入数据为止的整个过程，这一过程也是MapReduce的核心过程。

#### ***\*Reduce过程\****

Reduce接收<key,value>形式的数据流，形成<key,value>形式的数据输出，输出数据直接写入HDFS，具体的处理过程可由用户定义。

### ***\*MapReduce任务运行流程\****

#### ***\*MRv2基本组成\****

客服端（client）、MRAppMaster、Map Task和Reduce Task

#### ***\*Yarn基本组成\****

Yarn是一个资源管理平台，它监控和调度整个集群资源，并负责管理集群所有任务的运行和任务资源的分配，它的基本组成如下，

1) Resource Manager (RM)：运行于NameNode，为整个集群的资源调度器，它主要包括两个组件：Resource Schedule(资源调度器)和Applications Manager(应用程序管理器)。
Resource Schedule:当有应用程序已经注册需要运行时，ApplicationMaster会向它申请资源，而它会根据当时的资源和限制进行资源分配，它会产生一个container 资源描述(第4点)。
Applications Manager:它负责管理整个集群运行的所有任务，包括应用程序的提交，和 Resource Schedule 协商启动和监控ApplicationMaster，并在ApplicationMaster任务失败时在其他结点重启它。
2) NodeManager:运行于DataNode，监控并管理单个结点的计算资源，并定时向RM汇报结点的资源使用情况，在结点上有任务时，还负责对container 进行创建、运行状态的监控及最终销毁。
3) ApplicationMaster (AM)：负责对一个任务流程的调度、管理，包括任务注册、资源申请、以及和NodeManage通信以开启和杀掉任务等。
4) container: Yam 架构下对运算资源的一种描述，它封装了某个结点的多维度资源，包括CPU、RAM、Disk、Network等。当AM 向RM申请资源时，RM分配的资源就是以container表示的，Map task和 Reduce Task只能在所分配的container描述限制中运行。

(3) ***\*任务流程\****

 		 1) client 向ResourceManager提交任务。
2)ResourceManager分配该任务的第一个container，并通知相应的NodeManagerMRAppMaster。
3)NodeManager接收命令后，开辟一个container资源空间，并在container中启动相MRAppMaster.
4)MRAppMaster启动之后，第一步会向ResourceManager注册，这样用户可以直接MRAppMaster监控任务的运行状态；之后则直接由MRAppMaster调度任务运行，重复5)
8)，直到任务结束。
5)MRAppMaster以轮询的方式向 ResourceManager申请任务运行所需的资源。
6)一旦ResourceManager配给了资源，MRAppMaster便会与相应的NodeManager通让它划分Container并启动相应的任务(MapTask或ReduceTask)。
7) NodeManager准备好运行环境，启动任务。
8)各任务运行，并定时通过RPC协议向MRAppMaster汇报自己的运行状态和进度MRAppMaster也会实时地监控任务的运行，当发现某个Task假死或失败时，便杀死它重动任务。
9)任务完成，MRAppMaster向ResourceManager通信，注销并关闭自己。
